{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcMYQvxGlLtbcjw7EI6OTk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyadarshinivr19/Minors-Degree-Machine-Learning/blob/main/FMML_M1L2_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preparation**"
      ],
      "metadata": {
        "id": "78vWLoo2R59B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "NiBhloG1JevZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sv7Mcu38JFm5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "rng = np.random.default_rng(seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Dataset"
      ],
      "metadata": {
        "id": "OIgq4Px_PYDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.fetch_california_housing()\n",
        "# Dataset description\n",
        "print(dataset.DESCR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Af-YZUZCPW6U",
        "outputId": "26cd688b-e2fa-413f-8af5-84b97fc8c37a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _california_housing_dataset:\n",
            "\n",
            "California Housing dataset\n",
            "--------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 20640\n",
            "\n",
            "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
            "\n",
            "    :Attribute Information:\n",
            "        - MedInc        median income in block group\n",
            "        - HouseAge      median house age in block group\n",
            "        - AveRooms      average number of rooms per household\n",
            "        - AveBedrms     average number of bedrooms per household\n",
            "        - Population    block group population\n",
            "        - AveOccup      average number of household members\n",
            "        - Latitude      block group latitude\n",
            "        - Longitude     block group longitude\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "This dataset was obtained from the StatLib repository.\n",
            "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
            "\n",
            "The target variable is the median house value for California districts,\n",
            "expressed in hundreds of thousands of dollars ($100,000).\n",
            "\n",
            "This dataset was derived from the 1990 U.S. census, using one row per census\n",
            "block group. A block group is the smallest geographical unit for which the U.S.\n",
            "Census Bureau publishes sample data (a block group typically has a population\n",
            "of 600 to 3,000 people).\n",
            "\n",
            "A household is a group of people residing within a home. Since the average\n",
            "number of rooms and bedrooms in this dataset are provided per household, these\n",
            "columns may take surprisingly large values for block groups with few households\n",
            "and many empty houses, such as vacation resorts.\n",
            "\n",
            "It can be downloaded/loaded using the\n",
            ":func:`sklearn.datasets.fetch_california_housing` function.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
            "      Statistics and Probability Letters, 33 (1997) 291-297\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Orignal target values:\", dataset.target)\n",
        "\n",
        "dataset.target = dataset.target.astype(int)\n",
        "\n",
        "print(\"Target values after conversion:\", dataset.target)\n",
        "print(\"Input variables shape:\", dataset.data.shape)\n",
        "print(\"Output variables shape:\", dataset.target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UR85GdSPinD",
        "outputId": "761f34f4-91d4-4207-8fbb-4007e0ded382"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orignal target values: [4.526 3.585 3.521 ... 0.923 0.847 0.894]\n",
            "Target values after conversion: [4 3 3 ... 0 0 0]\n",
            "Input variables shape: (20640, 8)\n",
            "Output variables shape: (20640,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nearest Neighbours"
      ],
      "metadata": {
        "id": "XwyyIYg_QDf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NN1(traindata, trainlabel, query):\n",
        "    diff = (\n",
        "        traindata - query\n",
        "    )  # find the difference between features. Numpy automatically takes care of the size here\n",
        "    sq = diff * diff  # square the differences\n",
        "    dist = sq.sum(1)  # add up the squares\n",
        "    label = trainlabel[np.argmin(dist)]\n",
        "    return label\n",
        "\n",
        "\n",
        "def NN(traindata, trainlabel, testdata):\n",
        "    predlabel = np.array([NN1(traindata, trainlabel, i) for i in testdata])\n",
        "    return predlabel"
      ],
      "metadata": {
        "id": "ajAmqunoPq98"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Classifier"
      ],
      "metadata": {
        "id": "B7xRlqdLQF5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RandomClassifier(traindata, trainlabel, testdata):\n",
        "    classes = np.unique(trainlabel)\n",
        "    rints = rng.integers(low=0, high=len(classes), size=len(testdata))\n",
        "    predlabel = classes[rints]\n",
        "    return predlabel"
      ],
      "metadata": {
        "id": "3XMfPNCKQItU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "pOW2u7b2QafP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Accuracy(gtlabel, predlabel):\n",
        "    assert len(gtlabel) == len(\n",
        "        predlabel\n",
        "    ), \"Length of the ground-truth labels and predicted labels should be the same\"\n",
        "    correct = (\n",
        "        gtlabel == predlabel\n",
        "    ).sum()  # count the number of times the groundtruth label is equal to the predicted label.\n",
        "    return correct / len(gtlabel)"
      ],
      "metadata": {
        "id": "PFgRvVD1QXYK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting Data"
      ],
      "metadata": {
        "id": "QPTHQOsgQIRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split(data, label, percent):\n",
        "    # generate a random number for each sample\n",
        "    rnd = rng.random(len(label))\n",
        "    split1 = rnd < percent\n",
        "    split2 = rnd >= percent\n",
        "\n",
        "    split1data = data[split1, :]\n",
        "    split1label = label[split1]\n",
        "    split2data = data[split2, :]\n",
        "    split2label = label[split2]\n",
        "    return split1data, split1label, split2data, split2label"
      ],
      "metadata": {
        "id": "zN7GUEk6Qob_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Application**"
      ],
      "metadata": {
        "id": "EcGI-VOFQ-1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testdata, testlabel, alltraindata, alltrainlabel = split(\n",
        "    dataset.data, dataset.target, 20 / 100\n",
        ")\n",
        "print(\"Number of test samples:\", len(testlabel))\n",
        "print(\"Number of train samples:\", len(alltrainlabel))\n",
        "print(\"Percent of test data:\", len(testlabel) * 100 / len(dataset.target), \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmvWoF9HQs7m",
        "outputId": "4934de77-a5f1-4fdc-b068-331e01cb06ab"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test samples: 4144\n",
            "Number of train samples: 16496\n",
            "Percent of test data: 20.07751937984496 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata, trainlabel, valdata, vallabel = split(\n",
        "    alltraindata, alltrainlabel, 75 / 100)"
      ],
      "metadata": {
        "id": "lbO_m33bQzak"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainpred = NN(traindata, trainlabel, traindata)\n",
        "trainAccuracy = Accuracy(trainlabel, trainpred)\n",
        "print(\"Training accuracy using nearest neighbour algorithm:\", trainAccuracy*100, \"%\")\n",
        "\n",
        "trainpred = RandomClassifier(traindata, trainlabel, traindata)\n",
        "trainAccuracy = Accuracy(trainlabel, trainpred)\n",
        "print(\"Training accuracy using random classifier: \", trainAccuracy*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVYEpkaaQ6NG",
        "outputId": "524038d3-48a8-477b-d166-2272c74eba3e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy using nearest neighbour algorithm: 100.0 %\n",
            "Training accuracy using random classifier:  16.4375808538163 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valpred = NN(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy using nearest neighbour algorithm:\", valAccuracy*100, \"%\")\n",
        "\n",
        "\n",
        "valpred = RandomClassifier(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy using random classifier:\", valAccuracy*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GphoEc0RCNr",
        "outputId": "e88a385e-317e-4144-d0d6-888ffe212f50"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy using nearest neighbour algorithm: 34.10852713178294 %\n",
            "Validation accuracy using random classifier: 16.884689922480618 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata, trainlabel, valdata, vallabel = split(\n",
        "    alltraindata, alltrainlabel, 75 / 100)\n",
        "valpred = NN(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy using nearest neighbour algorithm:\", valAccuracy*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrR7LxeBRU3H",
        "outputId": "2beebb40-180a-4602-88db-81211184e253"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy using nearest neighbour algorithm: 34.048257372654156 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testpred = NN(alltraindata, alltrainlabel, testdata)\n",
        "testAccuracy = Accuracy(testlabel, testpred)\n",
        "\n",
        "print(\"Test accuracy:\", testAccuracy*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOC0MrzIRosL",
        "outputId": "f051b44e-9c42-4717-db87-34704fbe3a2e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 34.91795366795367 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Questions Set 1**"
      ],
      "metadata": {
        "id": "GJ6hh98oaklC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. How is the accuracy of the validation set affected if we increase the percentage of validation set? What happens when we reduce it?**"
      ],
      "metadata": {
        "id": "zfgbrCVuayua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "traindata, trainlabel, valdata, vallabel = split(\n",
        "    alltraindata, alltrainlabel, 30 / 100)\n",
        "valpred = NN(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy using nearest neighbour algorithm:\", valAccuracy*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-myvaKoRo9J",
        "outputId": "a14e6f3b-4dcd-412f-8303-ba175ae45ba7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy using nearest neighbour algorithm: 31.528113142462917 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata, trainlabel, valdata, vallabel = split(\n",
        "    alltraindata, alltrainlabel, 70 / 100)\n",
        "valpred = NN(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy using nearest neighbour algorithm:\", valAccuracy*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Lr_zj6WbGBm",
        "outputId": "a98f84ac-8fa8-4289-e5fa-c7bb9f43d2d0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy using nearest neighbour algorithm: 33.066502463054185 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata, trainlabel, valdata, vallabel = split(\n",
        "    alltraindata, alltrainlabel, 99.9 / 100)\n",
        "valpred = NN(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy using nearest neighbour algorithm:\", valAccuracy*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwPf2_APbKbF",
        "outputId": "35773bea-c0bb-42b9-b689-4d20026fdea0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy using nearest neighbour algorithm: 33.33333333333333 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata, trainlabel, valdata, vallabel = split(\n",
        "    alltraindata, alltrainlabel, 0.1 / 100)\n",
        "valpred = NN(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy using nearest neighbour algorithm:\", valAccuracy*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxT-GvxGbPAo",
        "outputId": "10a17505-0553-444b-b6c8-5873d4f58c0b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy using nearest neighbour algorithm: 32.073755079759806 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall, the validation accuracy seems to increase with increase in size of validation dataset percentage and decreases as we reduce the percentage."
      ],
      "metadata": {
        "id": "N8Cxn_o-b_W3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. How does the size of the train and validation set affect how well we can predict the accuracy on the test set using the validation set?**"
      ],
      "metadata": {
        "id": "6ZYHUzV7cK09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "traindata, trainlabel, valdata, vallabel = split(\n",
        "    alltraindata, alltrainlabel, 30 / 100)\n",
        "valpred = NN(traindata, trainlabel, valdata)\n",
        "testpred = NN(alltraindata, alltrainlabel, testdata)\n",
        "testAccuracy = Accuracy(testlabel, testpred)\n",
        "\n",
        "print(\"Test accuracy:\", testAccuracy*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPtDRMuwcpkp",
        "outputId": "f388bfc3-11fb-41a8-f1b4-3cbce29d9c6b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 34.91795366795367 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata, trainlabel, valdata, vallabel = split(\n",
        "    alltraindata, alltrainlabel, 30 / 100)\n",
        "valpred = NN(traindata, trainlabel, valdata)\n",
        "testpred = NN(alltraindata, alltrainlabel, testdata)\n",
        "testAccuracy = Accuracy(testlabel, testpred)\n",
        "\n",
        "print(\"Test accuracy:\", testAccuracy*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAz7PqZWcw6E",
        "outputId": "aa5904cf-e47e-4a1a-84e0-9db56e9e7f41"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 34.91795366795367 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata, trainlabel, valdata, vallabel = split(\n",
        "    alltraindata, alltrainlabel, 99.9 / 100)\n",
        "valpred = NN(traindata, trainlabel, valdata)\n",
        "testpred = NN(alltraindata, alltrainlabel, testdata)\n",
        "testAccuracy = Accuracy(testlabel, testpred)\n",
        "\n",
        "print(\"Test accuracy:\", testAccuracy*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCjRr98lc7lV",
        "outputId": "eb3603db-340f-4209-8f25-d7dfddf94629"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 34.91795366795367 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata, trainlabel, valdata, vallabel = split(\n",
        "    alltraindata, alltrainlabel, 0.1 / 100)\n",
        "valpred = NN(traindata, trainlabel, valdata)\n",
        "testpred = NN(alltraindata, alltrainlabel, testdata)\n",
        "testAccuracy = Accuracy(testlabel, testpred)\n",
        "\n",
        "print(\"Test accuracy:\", testAccuracy*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rTeayxgdGxy",
        "outputId": "b7ec8de0-a30e-468a-c7de-d0a20306fabb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 34.91795366795367 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test set accuracy does not seem to change with size of validation dataset percentage ."
      ],
      "metadata": {
        "id": "4Wa_Eo6fcZ75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. What do you think is a good percentage to reserve for the validation set so that thest two factors are balanced?**"
      ],
      "metadata": {
        "id": "6foqy2JbdbXd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One can allocate 30 percent for the validation dataset in order to balance the two factors."
      ],
      "metadata": {
        "id": "j95cK-wNdqM1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise**"
      ],
      "metadata": {
        "id": "DanJ3YCpxnF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "AW5FAVyEdaQ_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdata, testlabel, alltraindata, alltrainlabel = split(\n",
        "    dataset.data, dataset.target, 20 / 100\n",
        ")"
      ],
      "metadata": {
        "id": "oCpJExqlz4OU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing 1-Nearest Neighbor classifier\n",
        "knn_1 = KNeighborsClassifier(n_neighbors=1)\n",
        "knn_1.fit(alltraindata, alltrainlabel)\n",
        "\n",
        "y_pred_1 = knn_1.predict(testdata)\n",
        "\n",
        "# Calculating the accuracy for the 1-NN classifier\n",
        "accuracy_1 = accuracy_score(testlabel,y_pred_1)\n",
        "print(f\"Accuracy of 1-Nearest Neighbor classifier: {accuracy_1:.4f}\")\n",
        "\n",
        "# Implementing 3-Nearest Neighbor classifier\n",
        "knn_3 = KNeighborsClassifier(n_neighbors=3)\n",
        "knn_3.fit(alltraindata, alltrainlabel)\n",
        "\n",
        "# Implementing the 3-NN classifier\n",
        "y_pred_3 = knn_3.predict(testdata)\n",
        "\n",
        "# Calculating the accuracy for the 3-NN classifier\n",
        "accuracy_3 = accuracy_score(testlabel,y_pred_3)\n",
        "print(f\"Accuracy of 3-Nearest Neighbor classifier: {accuracy_3:.4f}\")\n",
        "\n",
        "# Comparing results\n",
        "if accuracy_1 > accuracy_3:\n",
        "    print(\"1-Nearest Neighbor is more accurate.\")\n",
        "elif accuracy_1 < accuracy_3:\n",
        "    print(\"3-Nearest Neighbor is more accurate.\")\n",
        "else:\n",
        "    print(\"Both classifiers have the same accuracy.\")"
      ],
      "metadata": {
        "id": "EfD_8nsKch6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2799fc9d-28d4-4b4d-fefb-7765a8b7dbd5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of 1-Nearest Neighbor classifier: 0.3498\n",
            "Accuracy of 3-Nearest Neighbor classifier: 0.3550\n",
            "3-Nearest Neighbor is more accurate.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multiple Splits**"
      ],
      "metadata": {
        "id": "ZgiVmPCa1P3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def AverageAccuracy(alldata, alllabel, splitpercent, iterations, classifier=NN):\n",
        "    accuracy = 0\n",
        "    for ii in range(iterations):\n",
        "        traindata, trainlabel, valdata, vallabel = split(\n",
        "            alldata, alllabel, splitpercent\n",
        "        )\n",
        "        valpred = classifier(traindata, trainlabel, valdata)\n",
        "        accuracy += Accuracy(vallabel, valpred)\n",
        "    return accuracy / iterations"
      ],
      "metadata": {
        "id": "c6KgCNL31PeU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_acc = AverageAccuracy(alltraindata, alltrainlabel, 75 / 100, 10, classifier=NN)\n",
        "print(\"Average validation accuracy:\", avg_acc*100, \"%\")\n",
        "testpred = NN(alltraindata, alltrainlabel, testdata)\n",
        "\n",
        "print(\"Test accuracy:\", Accuracy(testlabel, testpred)*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ38_kj82kC5",
        "outputId": "065e6198-3b79-417b-85c6-97d909826e59"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average validation accuracy: 34.32860224772855 %\n",
            "Test accuracy: 34.97901752653666 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Questions Set 2**"
      ],
      "metadata": {
        "id": "bfBjfzqP26Sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Does averaging the validation accuracy across multiple splits give more consistent results?**"
      ],
      "metadata": {
        "id": "INCeoFit3FLi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, averaging validation accuracy across multiple splits typically provides more consistent and reliable results."
      ],
      "metadata": {
        "id": "pmLqkjY43b1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Does it give more accurate estimate of test accuracy?**"
      ],
      "metadata": {
        "id": "IxGxDKeh3c2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, averaging validation accuracy across multiple splits, such as in cross-validation, generally provides a more accurate and reliable estimate of the true test accuracy of a model."
      ],
      "metadata": {
        "id": "oZgAASdt3o0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. What is the effect of the number of iterations on the estimate? Do we get a better estimate with higher iterations?**"
      ],
      "metadata": {
        "id": "uBswxyCk3xul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Almost every iteration of model being applied gives more or less give the same estimate, in the method we have used, however methods like K-Fold Cross Validation can give better estimates."
      ],
      "metadata": {
        "id": "UY08BU8n4Opg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Consider the results you got for the previous questions. Can we deal with a very small train dataset or validation dataset by increasing the iterations?**"
      ],
      "metadata": {
        "id": "n3AqyCIu4opO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Increasing the number of iterations in cross-validation or using other techniques to address small training or validation datasets can help mitigate some of the challenges associated with limited data, but it has limitations and might not fully address all issues."
      ],
      "metadata": {
        "id": "K2wB7fBl4tJZ"
      }
    }
  ]
}